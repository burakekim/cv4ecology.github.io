<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>People</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />

		<!-- Global site tag (gtag.js) - Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-DCEY6Y6YPV"></script>
		<script>
		  window.dataLayer = window.dataLayer || [];
		  function gtag(){dataLayer.push(arguments);}
		  gtag('js', new Date());

		  gtag('config', 'G-DCEY6Y6YPV');
		</script>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="index.html" class="logo"><strong>CV4Ecology Workshop</strong></a>
									<ul class="icons">
										<li><a href="https://twitter.com/cv4ecology" target="_blank" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
										<li><a href="https://www.youtube.com/@cv4ecology" target="_blank" class="icon brands fa-youtube"><span class="label">Twitter</span></a></li>
									</ul>
								</header>

							<!-- Content -->
								<section>
									<header class="main">
										<h1>People 2025</h1>
									</header>

									<span class="image main"><img src="images/camtraps.jpg" alt="" /></span>
									<hr />
									<div>
										<span>
										  <h3 style="display: inline;">People by year: </h3> 
										  [<a href="people2022.html">2022</a>] 
										  [<a href="people2023.html">2023</a>] 
										  [<a href="people2025.html">2025</a>]
										</span>
									  </div>
									<hr />
									<h3>Leadership Team</h3>

									<div class="bio-container">
							        	<span class="image left">
							        		<img src="images/sara2_square.jpg" alt="" width="100"/>
							        	</span>

										<h4>Sara Beery</h4>
								        <p class="bio">
								        	Sara Beery has always been passionate about the natural world, and she saw a need for technology-based approaches to conservation and sustainability challenges. This led her to pursue a PhD at Caltech, where her research focuses on computer vision for global-scale biodiversity monitoring. Her work is funded by an NSF Graduate Research Fellowship, a PIMCO Data Science Fellowship, and an Amazon AI4Science Fellowship. She works closely with Microsoft AI for Earth and Wildlife Insights (via Google Research) to translate her work into usable tools. Sara’s experiences as a professional ballerina, a queer woman, and a nontraditional student have taught her the value of unique and diverse perspectives in the research community. She’s passionate about increasing diversity and inclusion in STEM through mentorship, teaching, and outreach.
								        </p>
									</div>
									<div class="bio-container">
							        	<span class="image left">
							        		<img src="images/erico.jpeg" alt="" width="100"/>
							        	</span>

										<h4>Eric Orenstein</h4>
								        <p class="bio">
											Eric’s work lives at the intersection of ecology and computer vision, enabling unique studies of rapidly fluctuating marine environments. He uses imagery to study marine population dynamics, how they are impacted by their environment, and how they in turn influence the rest of the ecosystem. Eric has built and maintained imaging devices; worked with autonomous and remotely operated vehicles; executed field programs as a diver, small boat operator, and scientist aboardlarge research vessels; and used the data to study diverse organisms, from plankton to fish. Eric spends lots of time thinking about how to get robots to do useful things based on populations changes they encounter while underway.
								        </p>
									</div>

									<div class="bio-container">
										<span class="image left"><img src="images/pietro.jpg" alt="" width="100" /></span>

										<h4>Pietro Perona</h4>
										<p class="bio">
											Professor Perona's research focuses on vision: how do we see and how can we build machines that see. He is currently interested visual recognition, more specifically visual categorization. He is studying how machines can learn to recognize frogs, cars, faces and trees with minimal human supervision, and how machines can learn from human experts. His project 'Visipedia' has produced two smart device apps (iNaturalist and Merlin Bird ID) that anyone can use to recognize the species of plants and animals from a photograph.

											<br/><br/>
											In collaboration with Professors Anderson and Dickinson, Professor Perona is building vision systems and statistical techniques for measuring actions and activities in fruit flies and mice. This enables geneticists and neuroethologists to investigate the relationship between genes, brains and behavior.
											Professor Perona is also interested in studying how humans perform visual tasks, such as searching and recognizing image content. 
										</p>
									</div>
									<hr />

								<!--<h3>Mentors</h3>

									<div class="bio-container">
										<span class="image left">
											<img src="images/eli.jpg" alt="" width="50" />
										</span>

										<h4>Elijah Cole</h4>
										<p class="bio">
											Elijah is a Computing and Mathematical Sciences Ph.D. student in the Computational Vision Group at Caltech, advised by Pietro Perona. He's also involved in the Visipedia project. He's interested in computer vision, machine learning, and using these techniques to enable scientific progress in ecology and medicine. His work is supported by an NSF Graduate Research Fellowship.
										</p>
									</div>

									<div class="bio-container">
										<span class="image left"><img src="images/headshot4.jpg" alt="" width="100" /></span>

										<h4>Jason Parham</h4>
										<p class="bio">
											Jason Parham is a senior research engineer at Wild Me and works to apply the latest machine learning and computer vision algorithms in wildlife applications.  Jason holds a B.S. in Computer Science / Mathematics from Pepperdine University (2008), M.S. in Computer Science from RPI (2015), and a Ph.D. in Computer Science from RPI (2021; advisor <a href="https://www.cs.rpi.edu/~stewart/">Dr. Charles Stewart</a>).  Jason's doctoral research on <a href="https://scholar.google.com/citations?user=18vVhS8AAAAJ&hl=en&oi=ao">"Animal Detection for Photographic Censusing"</a> complements his applied work at Wild Me and offers a robust, end-to-end system for building large animal ID databases for conservation.  Jason is also the co-developer and current maintainer of <a href="https://github.com/WildMeOrg/wildbook-ia">Wildbook's Image Analysis (WBIA)</a> Python toolkit.  The machine learning algorithms available in WBIA are used to detect, classify, ID, and catalog animal populations worldwide and are available open-source on GitHub, PyPI, and as a pre-configured Docker container.
										</p>
									</div>

									<div class="bio-container">
										<span class="image left"><img src="images/bkellenb.jpg" alt="" width="100" /></span>

										<h4>Benjamin Kellenberger</h4>
										<p class="bio">
											Benjamin is a researcher with Devis Tuia at the ECEO lab of EPFL, Sion, Switzerland. He works in the fields of Remote Sensing, Computer Vision, and Machine Learning. His focus is primarily on animal conservation from above—using aerial imagery from airplanes, drones, etc. and machine-based tools to efficiently identify, count, and with that protect endangered animal species.
										</p>
									</div>
									<hr />
								-->
									<h3>Instructors</h3>
									
									<div class="bio-container">
										<span class="image left"><img src="images/bjorn2.jpg" alt="" width="100" /></span>

										<h4>Bjorn Lutjens</h4>
										<p class="bio">
											Björn is a postdoctoral associate in the MIT Department of Earth, Atmospheric, and Planetary Sciences. As running climate models can take multiple weeks on the world’s largest supercomputers, he is researching fast machine learning-based emulators, together with Prof. Raffaele Ferrari and Prof. Noelle Selin. He also advances methods in physics-informed machine learning and generative vision modeling for increasing the resolution of remote sensing-observable climate data. Previously, he has earned a Ph.D. with Prof. Dava Newman from MIT AeroAstro with a major/minor in Machine Learning and Earth System Modeling, earned an M.Sc. from MIT in reinforcement learning, and a B.Sc. from TUM in Engineering Science. He also windsurfs poorly.
										</p>
									</div>

									<div class="bio-container">
										<span class="image left">
											<img src="images/melisande.jpeg" alt="" width="50" />
										</span>

										<h4>Mélisande Teng</h4>
										<p class="bio">
											Mélisande Teng is a PhD candidate in Computer Science at Université de Montréal / Mila - Quebec AI Institute and her research focuses on applications of machine learning and remote sensing for biodiversity monitoring, in particular, bird and butterfly species distribution modeling and tree monitoring. She's passionate about bridging the machine learning and ecology communities and the general public. She holds a MSc in Mathematics, Vision and Learning (MVA) from ENS Paris-Saclay and a Msc in Management and Social Entrepreneurship from ESSEC Business School. She also likes writing and drawing comics. 
										</p>
									</div>
									<div class="bio-container">
										<span class="image left"><img src="images/julia.jpg" alt="" width="100" /></span>
										<h4>Julia Chae</h4>
										<p class="bio">
											Julia is a PhD student at MIT EECS advised by Prof Sara Beery, generously supported by the Viterbi Graduate Fellowship and the NSERC PGS-D Fellowship. Broadly, she is interested in developing robust computer vision and machine learning algorithms for practical use across various domains, particularly in the natural world. Her current research focuses on investigating how synthetic data can be leveraged to as a training data source for real-world vision models, specifically targeting issues like long-tailed distributions and fine-grained classification tasks.
										</p>
									</div>
									<div class="bio-container">
										<span class="image left"><img src="images/sam2.jpeg" alt="" width="100" /></span>
										<h4>Sam Lapp</h4>
										<p class="bio">
											Currently, I'm conducting pursuing a PhD in the Kitzes Lab at the University of Pittsburgh. My research focuses on developing tools for automated the recognition of biological sounds, and applying these tools to better understand ecological processes and support conservation. Ultimately, I'm driven by a desire to protect biodiversity.
										</p>
									</div>
									<div class="bio-container">
										<span class="image left"><img src="images/tarun.jpeg" alt="" width="100" /></span>

										<h4>Tarun Sharma</h4>
										<p class="bio">
											Tarun is a PhD student in the lab of Prof. Joseph Parker at Caltech. He works on monitoring ants in the Angeles National Forest by deploying custom in-house made multi-sensor camera traps in front of ant colonies, and using AI to count and track individual ants. He has also worked on methods to better use unlabeled data for deep sea animal detection in cases of long-tailed distributions as an intern at MBARI. Prior to this he worked in the lab of Prof. Michael Dickinson on studying the role of the neurons involved in the flight and gaze stabilization systems of the fruit fly. His research interests involve computer vision applications for ecology, conservation technology, animal monitoring and behavior. Outside of work Tarun loves spending time in nature, either surfing, hiking or exploring the city, traveling, music and food.  										
										</p>
									</div>
									<div class="bio-container">
										<span class="image left"><img src="images/neha.png" alt="" width="100" /></span>
										<h4>Neha Hulkund</h4>
										<p class="bio">
											Neha Hulkund is a second year PhD student at MIT advised by Prof. Sara Beery. She is interested in improving the robustness and efficiency of models through a data-centric lens. Previously, she completed her BS/MEng at MIT in Computer Science and Mathematics, with a concentration in Ancient and Medieval Studies.
										</p>
									</div>
									<div class="bio-container">
										<span class="image left"><img src="images/peter.jpeg" alt="" width="100" /></span>

										<h4>Peter van Lunteren</h4>
										<p class="bio">
											Peter is a tech-savvy ecologist and data scientist passionate about developing data-driven solutions to enhance the quality of ecological research. As the founder of Addax Data Science, he focuses on creating tools that allow ecologists to spend less time on tedious tasks and more time on conservation efforts. In addition to his work with Addax, Peter has contributed to several conservation initiatives and is currently involved with three key organizations: Smart Parks, which uses cutting-edge technologies to protect endangered wildlife; the Inclusion Foundation, which provides basic income to village communities in Uganda; and Sensing Clues, which offers ready-to-use technologies for data collection, integration, and analysis in nature conservation. Additionally, Peter developed EcoAssist, an open-source platform that enables the annotation and deployment of machine learning models for automated species detection in camera trap footage.
										</p>
									</div>
									<div class="bio-container">
										<span class="image left"><img src="images/shir.jpg" alt="" width="100" /></span>

										<h4>Shir Bar</h4>
										<p class="bio">
											Shir is a Ph.D. candidate at Tel Aviv University, co-advised by Roi Holzman (School of Zoology) and Shai Avidan (School of Electrical Engineering). Her research interests are in the application of computer vision for ecology, specifically for identifying animal behaviors. Coming from a background in marine ecology, she is particularly interested in the challenges of applying existing computer vision methods to underwater imagery. Shir holds an M.Sc in Ecology, Evolution, and Behavior from the Hebrew University of Jerusalem, which she completed at the Interuniversity Institute for Marine Sciences in Eilat; where she is now based. She has also worked in various international NGOs and has a rich background in fieldwork. Her experiences in and out of academia have made her feel there is a strong need for interdisciplinary research to integrate computer vision approaches into the ecological research pipeline.
										</p>
									</div>
									<hr />

								<!--<div class="bio-container">
										<span class="image left"><img src="images/surya.jpeg" alt="" width="100" /></span>
										<h4>Surya Narayanan Hari</h4>
										<p class="bio">
										Surya Narayanan is a PhD student studying Machine Learning. He is interested in biological applications and new model architectures. In his free time, he enjoys exploring LA, sports and gardening.
										</p>
									</div>
									<div class="bio-container">
										<span class="image left"><img src="images/manuel.jpeg" alt="" width="100" /></span>
										<h4>Manuel Knott</h4>
										<p class="bio">
										Manuel is a PhD student in Applied Machine Learning at ETH Zurich, conducting research at the Swiss Data Science Center and the Swiss Federal Laboratories for Materials Science and Technology. His work revolves around Computer Vision applications for food safety. Before his PhD, Manuel spent three years working in Industry as a Machine Learning Engineer. He is currently a visiting student researcher at the Caltech Vision Lab.
										</p>
									</div> -->
									<hr />

								</section>
						</div>
					</div>

				<!-- Sidebar -->
				<div id="sidebar">
						<div class="inner">

							<!-- Search -->
<!-- 								<section id="search" class="alt">
									<form method="post" action="#">
										<input type="text" name="query" id="query" placeholder="Search" />
									</form>
								</section> -->
							<!-- Menu -->
							<nav id="menu">
								<header class="major">
									<h2>Menu</h2>
								</header>
								<ul>
									<li><a href="index.html">Homepage</a></li>
									<li><a>Course Materials</a></li>
									<ul>
									<li><a href="course_details.html">Overview</a></li>
									<li><a href="course_content2023.html">Lectures and Syllabus</a></li>
									</ul>
									<li><a>People</a></li>
									<ul>
									<li><a href="students2025.html">Students</a></li>
									<li><a href="people2025.html">Instructors</a></li> 
									<li><a href="speakers2023.html">Speakers</a></li>
									</ul>
									<li><a href="important_dates.html">Important Dates</a></li>
									<li><a href="faq.html">FAQ</a></li>
									<li><a href="call_for_applications.html">Apply</a></li>

									<!--
									<li><a>2022</a></li>
									<ul>
									<li><a href="students2022.html">Students</a></li>
									<li><a href="speakers2022.html">Speakers</a></li>
									<li><a href="people2022.html">Instructors</a></li>
									<li><a href="course_content2022.html">Course Materials</a></li>
									</ul>
									<li><a>2023</a></li>
									<ul>
									<li><a href="students2025.html">Students</a></li>
									<li><a href="speakers2023.html">Speakers</a></li>
									<li><a href="people2023.html">Instructors</a></li>
									<li><a href="course_content2023.html">Course Materials</a></li>
									</ul>
									<li><a>2025</a></li>
									<ul>
									<li><a href="students2025.html">Students</a></li>
									<li><a href="speakers2025.html">Speakers</a></li>
									<li><a href="people2025.html">Instructors</a></li> 
									<li><a href="course_content2025.html">Course Materials</a></li>
									</ul>-->

									<!-- <li><a href="https://docs.google.com/spreadsheets/d/1IP4DWrmkhN5zny4ljq83HwBRuKe7gH3hDZSMXn8d__0/edit?usp=sharing">Schedule</a></li> -->
									<!--
										<li>
										<span class="opener">Apply</span>
										<ul>
											<li><a href="call_for_applications.html">Call for Applications</a></li>

											<li><a href="#">Application Portal</a></li>
										</ul>
									</li>
									-->
								</ul>
							</nav>
							<!-- Section -->
								<section>
									<header class="major">
										<h2>Get in touch</h2>
									</header>
									<ul class="contact">
										<li class="icon solid fa-envelope"><a href="mailto:cv4ecology@caltech.edu">cv4ecology@caltech.edu</a></li>
										<li class="icon brands fa-twitter"><a href="https://twitter.com/cv4ecology" target="_blank">@cv4ecology</a></li>
										<li class="icon brands fa-github"><a href="https://github.com/cv4ecology" target="_blank">contribute on GitHub</a></li>
										<li class="icon solid fa-envelope"><a href="https://forms.gle/WAD76JceCW9osDm97" target="_blank">Sign up for our mailing list!</a></li>
									</ul>
								</section>

							<!-- Footer -->
								<footer id="footer">
									<p class="copyright"> This material is based upon work supported by the National Science Foundation under Award No. 2330423. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.</p>
									<p class="copyright">&copy; California Institute of Technology.<br/>All rights reserved.<br/>Design: <a href="https://html5up.net" target="_blank">HTML5 UP</a>.</p>
								</footer>

						</div>
					</div>

			</div>


		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
